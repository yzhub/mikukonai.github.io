#!title:    C.计算机科学
#!date:     2019-10-20
#!authors:  
#!cover:    
#!type:     
#!tags:     

#!content

# 拾零

- [#(Chaitin常数)#](https://en.wikipedia.org/wiki/Chaitin%27s_constant)
- [#(布隆过滤器)#](https://zh.wikipedia.org/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)
- #(时序攻击)#

# 专题

## 三次握手

![ ](./image/assets/C/三次握手.png)

## 二进制反转

2016-09-08

在FFT算法中，有一步是对数组下标进行“码位倒置”，具体说来就是把一个数字的各二进制位倒过来写。

最直接的想法是使用移位操作将输入数字的各个二进制位提取出来，然后按照相反的顺序压入另一个数字。但是，如果设下标二进制位数为n，那么这种算法的时间复杂度是$O(n)$。

下面是一种更快、更适合硬件的“就地”码位倒置算法。对于八位无符号整数，只需要三步操作即可。

```:C
#include <stdio.h>

unsigned char bit_reverse(unsigned char i)
{
    unsigned char n = i;
    n = ( (n&0x55)<<1 ) | ( (n&0xaa)>>1 );
    n = ( (n&0x33)<<2 ) | ( (n&0xcc)>>2 );
    n = ( (n&0x0f)<<4 ) | ( (n&0xf0)>>4 );
    return n;
}

int main(void)
{
    unsigned char n = 0;

    while(1)
    {
        printf("Please input the number = ");
        scanf("%d", &n);
        n = bit_reverse(n);
        printf("The reversed number is  = %d\n", n);
    }

    return 0;
}
```

该算法可以将码位倒置算法的时间复杂度控制在$O(\mathrm {log}(n))$，挺机智的。

这个算法是在编写FFT算法的时候找到的。

**参考资料**

- [Bit-reversal permutation](https://en.wikipedia.org/wiki/Bit-reversal_permutation)
- [Bit Twiddling Hacks](http://graphics.stanford.edu/~seander/bithacks.html)

## 基于FFT的大数乘法算法

2018-09-10

大数乘法是很经典的一个问题，说简单也简单，说难也难。从最简单的错位相乘，到加入分治以提高效率，再到各种高效算法，是学习数值计算的很好的切入点。

大数乘法算法可以突破数据宽度的限制，保持运算结果的位数，因此在金融等场景中非常有用。在实现MikuRec解释器的时候，测试阶乘会遇到非常大的数字相乘，为了方便调试，打算使用大数相乘算法，取代JS语言提供的乘法。长远来看，这也有利于实现CAS之类的系统。

两个大整数相乘，本质上是卷积操作。卷积的时间复杂度是O(n<sup>2</sup>)。在数字位数很大的时候，效率不是很理想。

为了提高效率，可以利用卷积定理，通过快速傅里叶变换，将时间复杂度压缩到O(n*log(n))的级别。卷积定理指的是，两个序列卷积的傅里叶变换，等于两个序列傅里叶变换的按位相乘。因此，两个大数相乘，可以按照如下算法进行：

+ 对两个大数分别做FFT，得到两个新序列。
+ 两个序列按位相乘，得到傅里叶变换的乘积序列。这一步的时间复杂度是线性的。
+ 对乘积序列作傅里叶反变换，即为大数相乘结果。

```:javascript
// 2018.10.10 大数乘法
function bigIntMultiply(astr, bstr) {
    // 自适应FFT长度
    let maxlen = Math.max(astr.length, bstr.length) * 2;
    let loglen = Math.round(Math.log2(maxlen));
    let FFTSIZE = (loglen % 2 === 0) ? POW[loglen+2] : POW[loglen+1]; // 偶数POW
    // 字符串->复数序列
    let a = new Array(FFTSIZE);
    let b = new Array(FFTSIZE);
    for(let i = 0; i < FFTSIZE; i++) {
        aDigit = (i < astr.length) ? parseInt(astr[astr.length-1-i]) : 0;
        bDigit = (i < bstr.length) ? parseInt(bstr[bstr.length-1-i]) : 0;
        a[i] = new Complex(aDigit, 0);
        b[i] = new Complex(bDigit, 0);
    }
    // 傅氏变换
    let A = FFT(a, FFTSIZE);
    let B = FFT(b, FFTSIZE);
    // 卷积
    let C = new Array();
    for(let i = 0; i < FFTSIZE; i++) {
        let c = A[i].mul(B[i]);
        C.push(c);
    }
    let c = IFFT(C, FFTSIZE);
    // 以字符串输出
    return (function(n) {
        let numstr = '';
        let carry = 0;
        for(let i = 0; i < n.length; i++) {
            let c = Math.round(n[i].rep) + carry;
            if(c >= 0 && c <= 9) {
                numstr = c.toString() + numstr;
                carry = 0;
            }
            else {
                numstr = (c % 10).toString() + numstr;
                carry = Math.round((c - c % 10) / 10);
            }
        }
        return numstr.replace(/^0*/gi, '');
    })(c);
}
```

FFT涉及浮点数运算，存在精度问题。如果使用不涉及浮点数运算的快速数论变换（NTT），就可以避免这个问题。

**参考资料**

+ [Schönhage–Strassen algorithm](https://en.wikipedia.org/wiki/Sch%C3%B6nhage%E2%80%93Strassen_algorithm)
+ [大数乘法（快速傅立叶变换）](https://blog.csdn.net/u013351484/article/details/48739415)
+ [FFT详解&大数乘法](https://blog.csdn.net/ripped/article/details/70241716)


## 睡眠排序

2018-03-27灵感：前段时间在知乎上偶然看到一些奇葩的#(排序)#算法，就很想写一篇笔记把它们记下来。其中一种是#(睡眠排序)#，相当佛系的一款排序算法。Tim排序是一款效率较高且稳定的排序算法，但是比较复杂。[这篇文章](http://www.freebuf.com/vuls/62129.html)讲得很好，值得一读。

众所周知JavaScript是一款以单线程异步为特色的语言，使用内置函数setTimeout很容易实现睡眠排序。但是，不论是V8引擎的事件循环，还是操作系统提供的多线程机制，精确延时都是不可能的（除非使用RTOS或者硬件定时器绕开操作系统的调度）。睡眠排序这一玩具算法可以帮助我们理解事件循环机制。点击下面的乱序数组，使用睡眠排序对其进行排序。为了体现出明显的排序错误，程序将100个相同的排序任务加入任务队列，每个排序任务以10~1000ms的周期反复执行。数组后面的数字是排序次数。不要点太多次，否则可能会卡住。

点击排序：<span style="color:\#558bc4;" class="sleep_sort_demo" onclick="let counter=0;for(let i=1;i<100;i++){setInterval(()=>{counter++;let a=\[9,1,8,2,7,3,6,4,5,10,0\];let sorted=\[\];a.forEach(function(e,i,a){setTimeout(()=>sorted.push(e),e+2);});setTimeout(function(){$('.sleep_sort_demo').html(JSON.stringify(sorted)+counter);},100);}, i*10);}">\[9,1,8,2,7,3,6,4,5,10,0\]</span>

## fork炸弹

#(fork炸弹)#：见[维基百科](https://zh.wikipedia.org/wiki/Fork%E7%82%B8%E5%BC%B9)。

```
:(){ :|:& };:
```

## 基于大规模语料统计的新词发现

2017-10-16

> 本文是对顾森（Matrix67）文章 [http://www.csdn.net/article/2013-05-08/2815186]() 和 [http://www.matrix67.com/blog/archives/5044]() 的学习笔记

传统的新词发现方法有一个逻辑上的怪圈：新词发现依赖于分词结果，分词结果依赖于词库，然而新词并不存在于词库中，这样得到的“新词”结果就无法令人信任。为了跳出这个逻辑怪圈，基于大规模语料的新词发现方法抛弃了词库，对大规模语料中可能成词的片段进行分析，得到所有可能的分词结果，再与已有词库进行比对，得到新词。

**新词特征指标**

词是参与成句的最小完整单位。因此，判断一个短片段是否成词，需要从“最小”和“完整”两个方面入手。完整性显得更重要，因此首先考虑短片段组合的稳固程度。

**内部凝固度**

词是更细粒度的词稳定组合在一起形成的，因此使用**凝固度**这一指标衡量若干片段的组合出现的概率大小。

- 对于可能成词AB的片段A和B，两者的出现频率$P(A)$和$P(B)$。
- 若二者并不成词，也即在文本中完全随机出现，则词AB在文本中出现的概率应为$P(A)\cdot P(B)$。
- 而文本中AB的实际出现频率为$P(AB)$：若$P(AB)$远高于$P(A)\cdot P(B)$，那么可初步认为AB是一个成词组合。

按照这个标准，很容易找到诸如“忐忑”、“蜘蛛”、“蟑螂”、“彷徨”这样的双字**联绵词**，因为联绵词中单字单独出现的概率极低。

对于多字词而言，有多种划分片段的方式。划分方式不同，按照上述方法计算得到的$P(A)\cdot P(B)$就截然不同。

> 作为一个无知识库的抽词程序，我们并不知道“电影院”是“电影”加“院”得来的……如果我们把“电影院”看作是“电”加“影院”所得，由此得到的凝合程度会更高一些。

因此，并不能简单地用某一种划分计算得到的$P(A)\cdot P(B)$作为新词内部凝固度指标，而应枚举各种划分方式，选出**最小**的$P(A)\cdot P(B)$，计算$P(AB)$与$P(A)\cdot P(B)$的比值，作为可用的凝固度指标。凝固度指标实际上就是互信息。

> 在整个2400万字的数据中，“电影”一共出现了2774次，出现的概率约为0.000113。“院”字则出现了4797次，出现的概率约为0.0001969。如果两者之间真的毫无关系，它们恰好拼在了一起的概率就应该是0.000113×0.0001969=2.223E–8。但事实上，“电影院”在语料中一共出现了175次，出现概率约为7.183E–6，是预测值的300多倍。

> 类似地，统计可得“的”字的出现概率约为0.0166，因而“的”和“电影”随机组合到了一起的理论概率值为0.0166×0.000113=1.875E–6，这与“的电影”出现的真实概率很接近——真实概率约为1.6E–5，是预测值的8.5倍。

**运用自由度**

内部凝合并不是判断文本片段是否成词的充分条件。如果只考虑内部凝合度的话，并不能确定新词的外部边界，得到的新词很可能会“偏短”。例如：

> 考虑“被子”和“辈子”这两个片段。我们可以说“买被子”、“盖被子”、 “进被子”、“好被子”、“这被子”等，在“被子”前面加各种字；但“辈子”的用法却非常固定，除了“一辈子”、“这辈子”、“上辈子”、“下辈子”，基 本上“辈子”前面不能加别的字了。“辈子”这个文本片段左边可以出现的字太有限，以至于直觉上我们可能会认为，“辈子”并不单独成词，真正成词的其实是 “一辈子”、“这辈子”之类的整体。

因此，判断一个片段是否为新词，除了其内部的具有稳定的结构之外，它本身要足够“自由”去参与成句。换句话说就是，片段的左侧和右侧出现的词汇要有足够大的多样性。

描述“多样性”的指标就是**熵**。对于一个随机系统而言，它的每个状态都蕴含了一定的信息量，状态发生的概率越低，状态提供的信息量就越大。对系统中所有状态具备的信息量按发生概率进行加权平均，就得到了系统的信息熵。也就是说，信息熵是系统信息量的期望。信息熵越高，意味着系统内部的状态越丰富、系统越混乱；信息熵越低，意味着系统内部的状态越贫乏、系统越规律。

新词运用自由度的计算方法如下：

+ 提取左邻字和右邻字集合；
+ 计算每个左右邻字的出现频率并计算左右邻字信息熵；
+ 取二者较小者作为运用自由度指标。

之所以要取二者较小者作为自由度指标，是因为有些词具有固定前（后）缀的特性，例如“共产”（共产党、共产主义…）、“清华”（清华大学、清华学子…）、“夫斯基”这样的后缀词，而这样的词显然是不成词的。

> 在实际运用中你会发现，文本片段的凝固程度和自由程度，两种判断标准缺一不可。只看凝固程度的话，程序会找出“巧克”、“俄罗”、“颜六色”、“柴可夫”等实际上是“半个词”的片段；只看自由程度的话，程序则会把“吃了一顿”、“看了一遍”、 “睡了一晚”、“去了一趟”中的“了一”提取出来，因为它的左右邻字都太丰富了。

